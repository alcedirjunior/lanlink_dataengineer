{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97644642-1dd3-4850-a875-832a9eea0a66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Projeto Engenharia de Dados\n",
    "\n",
    "Para este projeto foi utilizado o Cluster do Databricks Runtime Version 13.3 com Spark 3.4.1 Scala 2.12\n",
    "Base de dados [\"Brazilian E-Commerce Public Dataset by Olist\" do Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)\n",
    "\n",
    "###8.1. Ingestão e Carregamento de Dados: \n",
    "\n",
    "8.1.1. Carregue o conjunto de dados no Databricks. \n",
    "\n",
    "8.1.2. Explore o esquema dos dados e faça ajustes conforme necessário. \n",
    "\n",
    "###8.2. Transformações de Dados: \n",
    "\n",
    "8.2.1. Realize transformações necessárias, como tratamento de valores nulos, conversões de tipos, etc. \n",
    "\n",
    "8.2.2. Adicione uma coluna calculada, por exemplo, o valor total de cada transação. \n",
    "\n",
    "8.2.3. Agregue os dados para obter estatísticas de vendas, por exemplo, o total de vendas por produto ou por categoria. \n",
    "\n",
    "8.2.4. Introduza uma regra mais complexa, como identificar padrões de comportamento de compra ao longo do tempo ou criar categorias personalizadas de produtos com base em determinados critérios. \n",
    "\n",
    "\n",
    "###8.3. Saída em Parquet e Delta: \n",
    "\n",
    "8.3.1. Grave os dados transformados e agregados em um formato Parquet para persistência eficiente. \n",
    "\n",
    "8.3.2. Grave os mesmos dados em formato Delta Lake para aproveitar as funcionalidades de versionamento e transações ACID. \n",
    "\n",
    "\n",
    "###8.4. Exploração Adicional (Opcional): \n",
    "\n",
    "8.4.1. Execute consultas exploratórias para entender melhor os dados e validar as transformações. \n",
    "\n",
    "8.4.2. Crie visualizações ou relatórios para comunicar insights. \n",
    "\n",
    "8.4.3. Agende o notebook para execução automática em intervalos regulares para garantir a atualização contínua dos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8177f1bd-3230-4382-ab38-c77cfb317c31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Library\n",
    "Importação das bibliotecas utilizadas nos notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378dcb82-3717-46be-892d-498887f2dff1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import os\n",
    "import tempfile\n",
    "from pyspark.sql.types import TimestampType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9046ea-3739-4ec6-8a97-d47964ac69d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Criação de base de dados\n",
    "Criação de bases de dados raw, tru e ref para dividir as transformações solicitadas no teste em camadas do modelo medalhão com camadas bronze, prata e ouro\n",
    "\n",
    "1. Bronze - Banco de dados raw\n",
    "2. Prata - Banco de dados tru (Trusted)\n",
    "3. Ouro - Banco de dados ref (refined)\n",
    "\n",
    "Os arquivos iniciais (csv) foram utilizados em camada temporária chamada aqui de Transient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc5265d-0c40-4d3a-9831-abf08aa3cf18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS raw;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d40d57b1-c9be-4978-95e8-11e6cf9ab11a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS tru;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac80737-7b3e-4047-b0ff-f4e696e09697",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS ref;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f4496b-aea6-4986-83fb-2877c6371152",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Parâmetros\n",
    "Parâmetros a serem utilizados nos notebooks\n",
    "\n",
    "Nestes parâmetros, adicionei o download de todos os arquivos csv da base \"Brazilian E-Commerce Public Dataset by Olist\", encontrado no Kaggle. Todos os arquivos foram hospedados em meu github para melhor uso neste teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fd7f45-c918-41ea-b7af-a8d88956a9c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lista de URLs dos arquivos ZIP\n",
    "urls = [\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_customers_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_geolocation_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_order_items_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_order_payments_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_order_reviews_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_orders_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_products_dataset.csv.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_sellers_dataset.zip\",\n",
    "    \"https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/product_category_name_translation.zip\"\n",
    "]\n",
    "\n",
    "# Pastas para cada camada\n",
    "folderTransient = 'dbfs:/datalake/transient/'\n",
    "folderRaw = \"dbfs:/datalake/raw/\"\n",
    "folderTru = \"dbfs:/datalake/tru/\"\n",
    "folderRef = \"dbfs:/datalake/ref/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a737452-839c-4e41-823b-67dab8da5245",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Criação das pastas para cada camada, onde serão gravados os arquivos csv, parquet e delta parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c79b0d1-47e6-4e3b-a0e1-21dd2ce0e0bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificar se a pasta de destino existe, caso contrário, criá-la\n",
    "try:\n",
    "    dbutils.fs.ls(folderTransient)\n",
    "except:\n",
    "    dbutils.fs.mkdirs(folderTransient)\n",
    "    print(f\"Pasta de destino '{folderTransient}' criada.\")\n",
    "\n",
    "# Verificar se a pasta de destino existe, caso contrário, criá-la\n",
    "try:\n",
    "    dbutils.fs.ls(folderRaw)\n",
    "except:\n",
    "    dbutils.fs.mkdirs(folderRaw)\n",
    "    print(f\"Pasta de destino '{folderRaw}' criada.\")   \n",
    "\n",
    "# Verificar se a pasta de destino existe, caso contrário, criá-la\n",
    "try:\n",
    "    dbutils.fs.ls(folderTru)\n",
    "except:\n",
    "    dbutils.fs.mkdirs(folderTru)\n",
    "    print(f\"Pasta de destino '{folderTru}' criada.\")   \n",
    "\n",
    "# Verificar se a pasta de destino existe, caso contrário, criá-la\n",
    "try:\n",
    "    dbutils.fs.ls(folderRef)\n",
    "except:\n",
    "    dbutils.fs.mkdirs(folderRef)\n",
    "    print(f\"Pasta de destino '{folderRef}' criada.\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1697aec5-3f31-49f9-8744-fb3bac67d75b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Transient\n",
    "Nesta etapa é realizado o download dos arquivos zip e extraído o conteúdo csv para a pasta de destino da transient. \n",
    "Em sequência é realizado a transformação do conteúdo para arquivos parquet e excluído os arquivos csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9837d412-392e-4d31-9ba3-113175b06e28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Função para baixar e extrair um arquivo ZIP\n",
    "def download_and_extract(url, dest_folder):\n",
    "    extracted_files = []\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            with ZipFile(BytesIO(response.content)) as thezip:\n",
    "                thezip.extractall(tmpdir)\n",
    "            for filename in os.listdir(tmpdir):\n",
    "                local_file = os.path.join(tmpdir, filename)\n",
    "                dbfs_file = os.path.join(dest_folder, filename)\n",
    "                dbutils.fs.cp(f'file:{local_file}', dbfs_file)\n",
    "                extracted_files.append(dbfs_file)\n",
    "        print(f\"Arquivos de '{url}' extraídos em: {dest_folder}\")\n",
    "    else:\n",
    "        print(f\"Falha no download do arquivo {url}: Status code\", response.status_code)\n",
    "    return extracted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ed744d-737b-4693-9a09-fd03642e14b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Converter CSV para Parquet\n",
    "def convert_csv_to_parquet(csv_paths, dest_folder_parquet):\n",
    "    for csv_path in csv_paths:\n",
    "        # Lendo o arquivo CSV\n",
    "        df = spark.read.option(\"header\", \"true\").csv(csv_path, inferSchema=True)\n",
    "\n",
    "        # Definindo o caminho de destino Parquet\n",
    "        parquet_path = csv_path.replace('.csv', '')\n",
    "        \n",
    "        # Salvando o DataFrame como Parquet\n",
    "        df.write.mode(\"overwrite\").parquet(parquet_path)\n",
    "\n",
    "        print(f\"Arquivo Parquet salvo em: {parquet_path}\")\n",
    "\n",
    "        # Deletar o arquivo CSV original\n",
    "        print(csv_path.replace(\"dbfs:\",\"\"))\n",
    "        dbutils.fs.rm(csv_path.replace(\"dbfs:\",\"\"), recurse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c97adf0-ec7a-477e-ad3e-d25fdb228d73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.1.1 Carregue o conjunto de dados no Databricks\n",
    "###Atividade 8.3.1 Grave os dados transformados e agregados em um formato Parquet para persistência eficiente\n",
    "Chamada das funções para download dos arquivos csv e transformação em arquivos parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c48d25-7c5f-4572-a47f-6cfb5264e711",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_customers_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_customers_dataset\n/datalake/transient/olist_customers_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_geolocation_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_geolocation_dataset\n/datalake/transient/olist_geolocation_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_order_items_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_order_items_dataset\n/datalake/transient/olist_order_items_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_order_payments_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_order_payments_dataset\n/datalake/transient/olist_order_payments_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_order_reviews_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_order_reviews_dataset\n/datalake/transient/olist_order_reviews_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_orders_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_orders_dataset\n/datalake/transient/olist_orders_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_products_dataset.csv.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_products_dataset\n/datalake/transient/olist_products_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/olist_sellers_dataset.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/olist_sellers_dataset\n/datalake/transient/olist_sellers_dataset.csv\nArquivos de 'https://github.com/alcedirjunior/lanlink_dataengineer/raw/main/Dados/product_category_name_translation.zip' extraídos em: dbfs:/datalake/transient/\nArquivo Parquet salvo em: dbfs:/datalake/transient/product_category_name_translation\n/datalake/transient/product_category_name_translation.csv\n"
     ]
    }
   ],
   "source": [
    "# Processar cada URL\n",
    "for url in urls:\n",
    "    csv_files = download_and_extract(url, folderTransient)\n",
    "    convert_csv_to_parquet(csv_files, folderTransient)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b9340d5-5f15-449b-a8d1-71c565fcfaa2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Raw\n",
    "Nesta etapa é realizado a leitura dos arquivos parquet da transient e gravação de arquivos delta parquet, gerando tabelas na base de dados raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3cf261c-d08b-4539-bd65-02993c86e45f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Função para converter DataFrame em tabela Delta\n",
    "def create_delta_table(df, table_name_camada):\n",
    "    if table_name_camada.startswith(\"tbl_raw\"):\n",
    "        delta_path = folderRaw + table_name_camada\n",
    "        table_full_name = f\"raw.{table_name_camada}\"\n",
    "        camada = \"raw\"    \n",
    "    if table_name_camada.startswith(\"tbl_tru\"):\n",
    "        delta_path = folderTru + table_name_camada\n",
    "        table_full_name = f\"tru.{table_name_camada}\"\n",
    "        camada = \"tru\"\n",
    "\n",
    "    if table_name_camada.startswith(\"tbl_ref\"):\n",
    "        delta_path = folderRef + table_name_camada\n",
    "        table_full_name = f\"ref.{table_name_camada}\"\n",
    "        camada = \"ref\"        \n",
    "        \n",
    "    # Salvar o DataFrame no formato Delta Lake\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_path)\n",
    "\n",
    "    # Verificar se a tabela já existe\n",
    "    table_exists = spark.sql(f\"SHOW TABLES IN {camada} LIKE '{table_name_camada}'\").count() \n",
    "\n",
    "    # Criar tabela na raw caso ela não exista\n",
    "    if table_exists == 0:\n",
    "        print(f\"Criando a tabela '{table_name_camada}'...\")\n",
    "        spark.sql(f\"CREATE TABLE {table_full_name} USING DELTA LOCATION '{delta_path}'\")\n",
    "\n",
    "    print(f\"Operação concluída para a tabela Delta '{table_name_camada}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df48e193-e0f5-4acb-911d-153c9412b3d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.3.2 Grave os mesmos dados em formato Delta Lake para aproveitar as funcionalidades de versionamento e transações ACID\n",
    "Chamada da função para geração dos delta parquet e tabelas na raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc73626-666f-4285-82b4-d51fb8a53b83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_raw_olist_customers_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_customers_dataset'.\ntbl_raw_olist_geolocation_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_geolocation_dataset'.\ntbl_raw_olist_order_items_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_order_items_dataset'.\ntbl_raw_olist_order_payments_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_order_payments_dataset'.\ntbl_raw_olist_order_reviews_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_order_reviews_dataset'.\ntbl_raw_olist_orders_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_orders_dataset'.\ntbl_raw_olist_products_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_products_dataset'.\ntbl_raw_olist_sellers_dataset\nOperação concluída para a tabela Delta 'tbl_raw_olist_sellers_dataset'.\ntbl_raw_product_category_name_translation\nOperação concluída para a tabela Delta 'tbl_raw_product_category_name_translation'.\n"
     ]
    }
   ],
   "source": [
    "#Listagem dos arquivos da transient\n",
    "subfoldersTransient = dbutils.fs.ls('dbfs:/datalake/transient/')\n",
    "\n",
    "# Processar cada subpasta\n",
    "for folder in subfoldersTransient:\n",
    "    if folder.isDir():\n",
    "        # Nome da tabela baseado no nome da subpasta\n",
    "        table_name = \"tbl_raw_\" + os.path.basename(folder.path.rstrip('/'))\n",
    "        print(table_name)\n",
    "        \n",
    "        # Caminho para os arquivos Parquet\n",
    "        parquet_path = folder.path\n",
    "\n",
    "        # Ler arquivos Parquet da subpasta\n",
    "        df = spark.read.parquet(parquet_path)\n",
    "\n",
    "        # Criar tabela Delta\n",
    "        create_delta_table(df, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "606b5c0b-d40b-4f9b-9037-e239df189d66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.1.2 Explore o esquema dos dados e faça ajustes conforme necessário\n",
    "Visualização dos schemas dos arquivos na raw para ajustes na próxima camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3984057f-9b0e-49b8-844a-d28f7c8d5d23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema para tbl_raw_olist_customers_dataset:\nroot\n |-- customer_id: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n\nEsquema para tbl_raw_olist_geolocation_dataset:\nroot\n |-- geolocation_zip_code_prefix: integer (nullable = true)\n |-- geolocation_lat: double (nullable = true)\n |-- geolocation_lng: double (nullable = true)\n |-- geolocation_city: string (nullable = true)\n |-- geolocation_state: string (nullable = true)\n\nEsquema para tbl_raw_olist_order_items_dataset:\nroot\n |-- order_id: string (nullable = true)\n |-- order_item_id: integer (nullable = true)\n |-- product_id: string (nullable = true)\n |-- seller_id: string (nullable = true)\n |-- shipping_limit_date: timestamp (nullable = true)\n |-- price: double (nullable = true)\n |-- freight_value: double (nullable = true)\n\nEsquema para tbl_raw_olist_order_payments_dataset:\nroot\n |-- order_id: string (nullable = true)\n |-- payment_sequential: integer (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- payment_installments: integer (nullable = true)\n |-- payment_value: double (nullable = true)\n\nEsquema para tbl_raw_olist_order_reviews_dataset:\nroot\n |-- review_id: string (nullable = true)\n |-- order_id: string (nullable = true)\n |-- review_score: string (nullable = true)\n |-- review_comment_title: string (nullable = true)\n |-- review_comment_message: string (nullable = true)\n |-- review_creation_date: string (nullable = true)\n |-- review_answer_timestamp: string (nullable = true)\n\nEsquema para tbl_raw_olist_orders_dataset:\nroot\n |-- order_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n\nEsquema para tbl_raw_olist_products_dataset:\nroot\n |-- product_id: string (nullable = true)\n |-- product_category_name: string (nullable = true)\n |-- product_name_lenght: integer (nullable = true)\n |-- product_description_lenght: integer (nullable = true)\n |-- product_photos_qty: integer (nullable = true)\n |-- product_weight_g: integer (nullable = true)\n |-- product_length_cm: integer (nullable = true)\n |-- product_height_cm: integer (nullable = true)\n |-- product_width_cm: integer (nullable = true)\n\nEsquema para tbl_raw_olist_sellers_dataset:\nroot\n |-- seller_id: string (nullable = true)\n |-- seller_zip_code_prefix: integer (nullable = true)\n |-- seller_city: string (nullable = true)\n |-- seller_state: string (nullable = true)\n\nEsquema para tbl_raw_product_category_name_translation:\nroot\n |-- product_category_name: string (nullable = true)\n |-- product_category_name_english: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "def print_delta_schemas(folderRaw):\n",
    "    # Listar todos os arquivos e diretórios no caminho fornecido\n",
    "    items = dbutils.fs.ls(folderRaw)\n",
    "    \n",
    "    for item in items:\n",
    "        # Verificar se é um diretório\n",
    "        if item.isDir():\n",
    "            # Caminho para os arquivos Delta dentro do diretório\n",
    "            delta_path = item.path\n",
    "            \n",
    "            try:\n",
    "                # Tentar ler o diretório como um DataFrame Delta\n",
    "                df = spark.read.format(\"delta\").load(delta_path)\n",
    "                \n",
    "                # Imprimir o nome do diretório e o esquema do DataFrame\n",
    "                print(f\"Esquema para {os.path.basename(delta_path.rstrip('/'))}:\")\n",
    "                df.printSchema()\n",
    "            except Exception as e:\n",
    "                print(f\"Não foi possível ler o diretório {delta_path} como Delta: {e}\")\n",
    "\n",
    "# Chamar a função com o caminho desejado\n",
    "print_delta_schemas(folderRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c812f4-e30e-4e38-b617-21c9e0c14e7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Trusted\n",
    "Nesta etapa é realizado os tratamentos de dados, tipagem, nome de colunas, colunas cálculadas, etc, gravando os arquivos em delta parquet e na base de dados tru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ce08f1-98ef-4062-b94f-ab4e35db0fa6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.1.2 Explore o esquema dos dados e faça ajustes conforme necessário\n",
    "Tratado o nome de todas as colunas nas tabelas\n",
    "\n",
    "###Atividade 8.2.1 Realize transformações necessárias, como tratamento de valores nulos, conversões de tipos, etc\n",
    "Tratado valores nulos e conversões de tipos na tabela tru.tbl_tru_comentarios_pedido_venda, linha 37 do próximo notebook\n",
    "\n",
    "Tratado categoria com valor nulo na tabela tru.tbl_tru_produto na linha 65\n",
    "\n",
    "###Atividade 8.2.2 Adicione uma coluna calculada, por exemplo, o valor total de cada transação\n",
    "Adicionado coluna calculada na tabela tru.tbl_tru_pedido_venda_item, linha 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959febcb-5e3b-4ca8-9eac-10e1d5a21aee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transformation_tables(table_name):\n",
    "    raw_folder = folderRaw + table_name\n",
    "\n",
    "    # Ler os arquivos do Delta Parquet para um DataFrame do Spark\n",
    "    df = spark.read.format(\"delta\").load(raw_folder)\n",
    "\n",
    "    if table_name == 'tbl_raw_olist_customers_dataset':\n",
    "        table_name_tru = 'tbl_tru_clientes'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id\",\"id_unico\",\"cep_prefixo\",\"cidade\",\"estado\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "    \n",
    "    if table_name == 'tbl_raw_olist_geolocation_dataset':\n",
    "        table_name_tru = 'tbl_tru_clientes_geolocalizacao'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"cep_prefixo\",\"latitude\",\"longitude\",\"cidade\",\"estado\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "    \n",
    "    if table_name == 'tbl_raw_olist_order_items_dataset':\n",
    "        table_name_tru = 'tbl_tru_pedido_venda_item'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id_pedido_venda\",\"id_item_pedido_venda\",\"id_produto\",\"id_vendedor\",\"data_limite_envio\",\"valor_pedido_venda\",\"valor_frete\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "        # Adicionar uma nova coluna com a soma de \"valor_pedido_venda\" e \"valor_frete\"\n",
    "        df = df.withColumn(\"total_pedido\", col(\"valor_pedido_venda\") + col(\"valor_frete\")) \n",
    "    \n",
    "    if table_name == 'tbl_raw_olist_order_payments_dataset':\n",
    "        table_name_tru = 'tbl_tru_ordem_pagamento'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id_ordem_pagamento\",\"sequencia_pagamento\",\"tipo\",\"qtd_parcelas\",\"valor\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "    \n",
    "    if table_name == 'tbl_raw_olist_order_reviews_dataset':\n",
    "        table_name_tru = 'tbl_tru_comentarios_pedido_venda'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id_comentario\",\"id_pedido_venda\",\"score\",\"titulo_comentario\",\"mensagem_comentario\",\"data_criacao\",\"data_resposta\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "        # Substituir 'NULL' por valores nulos em colunas específicas e corrigir algumas tipagens\n",
    "        df = df.withColumn(\"id_pedido_venda\", when(col(\"id_pedido_venda\") == \"NULL\", None).otherwise(col(\"id_pedido_venda\"))) \\\n",
    "                .withColumn(\"score\", when(col(\"score\") == \"NULL\", None).otherwise(col(\"score\")).cast(IntegerType())) \\\n",
    "                .withColumn(\"titulo_comentario\", when(col(\"titulo_comentario\") == \"NULL\", None).otherwise(col(\"titulo_comentario\"))) \\\n",
    "                .withColumn(\"mensagem_comentario\", when(col(\"mensagem_comentario\") == \"NULL\", None).otherwise(col(\"mensagem_comentario\")))\\\n",
    "                .withColumn(\"data_criacao\", when(col(\"data_criacao\") == \"NULL\", None).otherwise(col(\"data_criacao\")).cast(TimestampType()))\\\n",
    "                .withColumn(\"data_resposta\", when(col(\"data_resposta\") == \"NULL\", None).otherwise(col(\"data_resposta\")).cast(TimestampType()))  \n",
    "    \n",
    "    if table_name == 'tbl_raw_olist_orders_dataset':\n",
    "        table_name_tru = 'tbl_tru_pedido_venda'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id_pedido_venda\",\"id_cliente\",\"status_pedido_venda\",\"data_pedido_venda\",\"data_aprovacao_pagamento\",\"data_postagem\",\"data_entrega\",\"data_estimada_entrega\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "    \n",
    "    if table_name == 'tbl_raw_olist_products_dataset':\n",
    "        table_name_tru = 'tbl_tru_produto'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id_produto\",\"nome_categoria\",\"nome_produto_qtd_caracteres\",\"descricao_produto_qtd_caracteres\",\"qtd_fotos\",\"peso\",\"tamanho\",\"altura\",\"largura\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "        #Tratamento de valores nulos\n",
    "        df = df.withColumn(\"nome_categoria\", when(col(\"nome_categoria\").isNull(), \"Categoria nao cadastrada\").otherwise(col(\"nome_categoria\")))          \n",
    "        \n",
    "    if table_name == 'tbl_raw_olist_sellers_dataset':\n",
    "        table_name_tru = 'tbl_tru_vendedores'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"id_vendedor\",\"cep_prefixo\",\"cidade\",\"estado\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)    \n",
    "\n",
    "    if table_name == 'tbl_raw_product_category_name_translation':\n",
    "        table_name_tru = 'tbl_tru_produto_traducao_nome_categoria'\n",
    "        # Novos nomes para as colunas\n",
    "        new_column_names = [\"nome_categoria\",\"nome_categoria_ingles\"]\n",
    "        # Renomear todas as colunas\n",
    "        df = df.toDF(*new_column_names)\n",
    "    \n",
    "    if 'table_name_tru' in locals():\n",
    "        # Se a variável existe, chame a função create_delta_table\n",
    "        create_delta_table(df, table_name_tru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38fde1fb-f64e-4263-914e-087ab7f6eff7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_raw_olist_customers_dataset\nOperação concluída para a tabela Delta 'tbl_tru_clientes'.\ntbl_raw_olist_geolocation_dataset\nOperação concluída para a tabela Delta 'tbl_tru_clientes_geolocalizacao'.\ntbl_raw_olist_order_items_dataset\nOperação concluída para a tabela Delta 'tbl_tru_pedido_venda_item'.\ntbl_raw_olist_order_payments_dataset\nOperação concluída para a tabela Delta 'tbl_tru_ordem_pagamento'.\ntbl_raw_olist_order_reviews_dataset\nOperação concluída para a tabela Delta 'tbl_tru_comentarios_pedido_venda'.\ntbl_raw_olist_orders_dataset\nOperação concluída para a tabela Delta 'tbl_tru_pedido_venda'.\ntbl_raw_olist_products_dataset\nOperação concluída para a tabela Delta 'tbl_tru_produto'.\ntbl_raw_olist_sellers_dataset\nOperação concluída para a tabela Delta 'tbl_tru_vendedores'.\ntbl_raw_product_category_name_translation\nOperação concluída para a tabela Delta 'tbl_tru_produto_traducao_nome_categoria'.\n"
     ]
    }
   ],
   "source": [
    "# Processar cada subpasta\n",
    "subfoldersRaw = dbutils.fs.ls('dbfs:/datalake/raw/') \n",
    "\n",
    "for folder in subfoldersRaw:\n",
    "    if folder.isDir():\n",
    "        # Nome da tabela baseado no nome da subpasta\n",
    "        table_name = os.path.basename(folder.path.rstrip('/'))\n",
    "        print(table_name)\n",
    "\n",
    "        transformation_tables(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ab4b30a-0cd1-45bb-a53a-9d5593fd08bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Refined - Relatórios\n",
    "Nesta etapa eu li algumas tabelas da camada tru para geração de tabelas de relatórios, gravando em arquivos delta parquet e na base de dados ref."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc77bb8-7311-483c-8b13-dd08f8f44719",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.2.3 Agregue os dados para obter estatísticas de vendas, por exemplo, o total de vendas por produto ou por categoria\n",
    "Gerado a tabela ref.tbl_ref_total_vendido_categoria com total vendido em $ por categoria de produto.\n",
    "\n",
    "É possível verificar os valores para a categoria \"Categoria nao cadastrada\", tratada na camada tru para valores nulos no campo nome_categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba885eab-e194-4456-998c-b7715a3afadd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operação concluída para a tabela Delta 'tbl_ref_total_vendido_categoria'.\n"
     ]
    }
   ],
   "source": [
    "#Criando relatório de total de vendas por categoria\n",
    "df = spark.sql(\"select pro.nome_categoria categoria, round(sum(pedi.total_pedido), 2) valor_total_vendido from tru.tbl_tru_pedido_venda_item pedi left join tru.tbl_tru_produto pro on pedi.id_produto = pro.id_produto group by 1 order by 2 desc\")\n",
    "table_name_ref = \"tbl_ref_total_vendido_categoria\"\n",
    "create_delta_table(df, table_name_ref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74dccb2-a669-42e3-a994-2b0f1c79dbf0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.2.3 Agregue os dados para obter estatísticas de vendas, por exemplo, o total de vendas por produto ou por categoria\n",
    "Gerado a tabela ref.tbl_ref_total_vendido_periodo para trazer os totais em $ por período de mês e ano. Foi utilizado a coluna calculada total_pedido gerada na camada tru, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc988b8-90a9-47e9-8468-70c697ffd83a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operação concluída para a tabela Delta 'tbl_ref_total_vendido_periodo'.\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select date_format(ped.data_pedido_venda, 'yyyy/MM') periodo, round(sum(pedi.total_pedido), 2) valor_total_vendido from tru.tbl_tru_pedido_venda_item pedi left join tru.tbl_tru_pedido_venda ped on pedi.id_pedido_venda = ped.id_pedido_venda group by 1 order by 1 desc\")\n",
    "table_name_ref = \"tbl_ref_total_vendido_periodo\"\n",
    "create_delta_table(df, table_name_ref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c0d37c4-4dad-4a60-9329-344a3cfdd10d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.2.4 Introduza uma regra mais complexa, como identificar padrões de comportamento de compra ao longo do tempo ou criar categorias personalizadas de produtos com base em determinados critérios. \n",
    "Para esta atividade criei uma métrica onde traz a média de dias entre a geração de novos pedidos de venda por vendedor, a fim de analisar a performance de cada vendedor.\n",
    "\n",
    "1. Primeiramente coloquei em um dataframe a junção das tabelas de pedido de vendas para buscar a data do pedido de venda e o id do vendedor\n",
    "2. Criei novas colunas dia_semana e mes no dataframe\n",
    "3. Utilizei as funções Window.partitionBy, lag e datediff para criar as colunas data_pedido_venda_anterior e diferenca_dias_entre_pedidos_venda, sendo a última com o valor cálculado entre os pedidos de venda\n",
    "4. Gravei o dataframe em uma view temporária view_pedido_venda\n",
    "5. Utilizei uma consulta sql na view para trazer a média de dias entre os pedidos para cada id_vendedor e gravei em uma tabela delta parquet chamada ref.tbl_ref_vendedor_media_dias_entre_vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1899ef43-81a3-4a78-9d28-e6e38b21a391",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operação concluída para a tabela Delta 'tbl_ref_vendedor_media_dias_entre_vendas'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.sql(\"\"\"\n",
    "               select ped.*, pedi.id_produto, pedi.id_vendedor\n",
    "               from tru.tbl_tru_pedido_venda ped left \n",
    "               join tru.tbl_tru_pedido_venda_item pedi \n",
    "                on ped.id_pedido_venda = pedi.id_pedido_venda where ped.status_pedido_venda not in ('unavailable','canceled')\n",
    "               \"\"\")\n",
    "df = df.withColumn(\"dia_semana\", dayofweek(col(\"data_pedido_venda\")))\n",
    "df = df.withColumn(\"mes\", month(col(\"data_pedido_venda\")))\n",
    "\n",
    "windowSpec = Window.partitionBy(\"id_vendedor\").orderBy(\"data_pedido_venda\")\n",
    "\n",
    "df = df.withColumn(\"data_pedido_venda_anterior\", lag(\"data_pedido_venda\", 1).over(windowSpec))\n",
    "df = df.withColumn(\"diferenca_dias_entre_pedidos_venda\", datediff(\"data_pedido_venda\", \"data_pedido_venda_anterior\"))\n",
    "\n",
    "df.createOrReplaceTempView(\"view_pedido_venda\")\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "               select \n",
    "                    id_vendedor\n",
    "                    ,round(avg(diferenca_dias_entre_pedidos_venda), 0) media_dias_entre_vendas\n",
    "                from view_pedido_venda vped\n",
    "                where id_vendedor is not null\n",
    "                group by 1\n",
    "                order by 2 desc\n",
    "               \"\"\")\n",
    "\n",
    "table_name_ref = \"tbl_ref_vendedor_media_dias_entre_vendas\"\n",
    "create_delta_table(df, table_name_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "facf6fde-9298-4f1e-ac62-ff8497798fde",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.4.1 Execute consultas exploratórias para entender melhor os dados e validar as transformações\n",
    "Realizado uma consulta sql validando a quantidade de registros de pedidos de venda entre as camadas raw e tru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88a216f4-16ba-497f-91f9-5c4c30e309a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_pedidos_venda_raw</th><th>total_pedidos_venda_tru</th></tr></thead><tbody><tr><td>99441</td><td>99441</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         99441,
         99441
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 104
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_pedidos_venda_raw",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_pedidos_venda_tru",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select\n",
    "(select count(*) from raw.tbl_raw_olist_orders_dataset) total_pedidos_venda_raw,\n",
    "(select count(*) from tru.tbl_tru_pedido_venda) total_pedidos_venda_tru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3577461-1ff5-43cc-9a2a-9232c74f2013",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Atividade 8.4.1 Execute consultas exploratórias para entender melhor os dados e validar as transformações\n",
    "Realizado consulta sql para validar o valor total do pedido de venda entre as camadas raw, tru e ref, visto que na camada tru foi gerado uma coluna calculada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "646b0e7c-3f2c-43e7-92d2-8de1fd0da1c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>total_pedido_raw</th><th>total_pedido_tru</th><th>total_pedido_ref</th></tr></thead><tbody><tr><td>1.584355324E7</td><td>1.584355324E7</td><td>1.584355324E7</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1.584355324E7,
         1.584355324E7,
         1.584355324E7
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 105
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "total_pedido_raw",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_pedido_tru",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_pedido_ref",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select\n",
    "(select round(sum(price+freight_value), 2) from raw.tbl_raw_olist_order_items_dataset) total_pedido_raw\n",
    ",(select round(sum(total_pedido), 2) from tru.tbl_tru_pedido_venda_item) total_pedido_tru\n",
    ",(select round(sum(valor_total_vendido), 2) from ref.tbl_ref_total_vendido_categoria) total_pedido_ref\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1dcbfd0-cd6b-41e7-8633-5745b36aa3d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###8.4.2 Crie visualizações ou relatórios para comunicar insights. \n",
    "Criado gráfico para análise de faturamento por período"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ee1149-8835-47ce-82bc-5c0d4fe9a8ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>periodo</th><th>valor_total_vendido</th></tr></thead><tbody><tr><td>2018/09</td><td>166.46</td></tr><tr><td>2018/08</td><td>1003308.47</td></tr><tr><td>2018/07</td><td>1058728.03</td></tr><tr><td>2018/06</td><td>1022677.11</td></tr><tr><td>2018/05</td><td>1149781.82</td></tr><tr><td>2018/04</td><td>1159698.04</td></tr><tr><td>2018/03</td><td>1155126.82</td></tr><tr><td>2018/02</td><td>986908.96</td></tr><tr><td>2018/01</td><td>1107301.89</td></tr><tr><td>2017/12</td><td>863547.23</td></tr><tr><td>2017/11</td><td>1179143.77</td></tr><tr><td>2017/10</td><td>769312.37</td></tr><tr><td>2017/09</td><td>720398.91</td></tr><tr><td>2017/08</td><td>668204.6</td></tr><tr><td>2017/07</td><td>584971.62</td></tr><tr><td>2017/06</td><td>502963.04</td></tr><tr><td>2017/05</td><td>586190.95</td></tr><tr><td>2017/04</td><td>412422.24</td></tr><tr><td>2017/03</td><td>432048.59</td></tr><tr><td>2017/02</td><td>286280.62</td></tr><tr><td>2017/01</td><td>137188.49</td></tr><tr><td>2016/12</td><td>19.62</td></tr><tr><td>2016/10</td><td>56808.84</td></tr><tr><td>2016/09</td><td>354.75</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2018/09",
         166.46
        ],
        [
         "2018/08",
         1003308.47
        ],
        [
         "2018/07",
         1058728.03
        ],
        [
         "2018/06",
         1022677.11
        ],
        [
         "2018/05",
         1149781.82
        ],
        [
         "2018/04",
         1159698.04
        ],
        [
         "2018/03",
         1155126.82
        ],
        [
         "2018/02",
         986908.96
        ],
        [
         "2018/01",
         1107301.89
        ],
        [
         "2017/12",
         863547.23
        ],
        [
         "2017/11",
         1179143.77
        ],
        [
         "2017/10",
         769312.37
        ],
        [
         "2017/09",
         720398.91
        ],
        [
         "2017/08",
         668204.6
        ],
        [
         "2017/07",
         584971.62
        ],
        [
         "2017/06",
         502963.04
        ],
        [
         "2017/05",
         586190.95
        ],
        [
         "2017/04",
         412422.24
        ],
        [
         "2017/03",
         432048.59
        ],
        [
         "2017/02",
         286280.62
        ],
        [
         "2017/01",
         137188.49
        ],
        [
         "2016/12",
         19.62
        ],
        [
         "2016/10",
         56808.84
        ],
        [
         "2016/09",
         354.75
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 106
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "periodo",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "valor_total_vendido",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (select * from ref.tbl_ref_total_vendido_periodo) SELECT `periodo`,SUM(`valor_total_vendido`) `column_f7e94da27` FROM q GROUP BY `periodo`",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "periodo",
             "id": "column_f7e94da26"
            },
            "y": [
             {
              "column": "valor_total_vendido",
              "id": "column_f7e94da27",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "hideXAxis": false,
           "hideYAxes": false,
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": ""
           },
           "seriesOptions": {
            "column_f7e94da27": {
             "name": "valor_total_vendido",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": true,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "title": {
             "text": "Período"
            },
            "type": "-"
           },
           "yAxis": [
            {
             "title": {
              "text": "Total Vendas $"
             },
             "type": "-"
            },
            {
             "opposite": true,
             "title": {
              "text": null
             },
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "0bb8bc27-db23-458d-8e34-be06570bd9ad",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 23.625,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "finished",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "periodo",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "periodo",
           "type": "column"
          },
          {
           "alias": "column_f7e94da27",
           "args": [
            {
             "column": "valor_total_vendido",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from ref.tbl_ref_total_vendido_periodo"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "c2ee1149-8835-47ce-82bc-5c0d4fe9a8ce",
       "elementType": "command",
       "guid": "3386ae37-ac07-4f6d-be24-80702fd0d0dc",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": false,
        "titleAlign": "center"
       },
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": false
     },
     "nuid": "703f07be-3f18-472d-9bdf-311c6e54ae25",
     "origId": 3412048486130694,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3412048486130695,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
